{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbb365a-59a0-43e6-a493-dadc874bb72c",
   "metadata": {},
   "source": [
    "# Web Scraping Exercise\n",
    "\n",
    "Web Scraping allows you to gather large volumes of data from diverse and real-time online sources. This data can be crucial for enriching your datasets, filling in gaps, and providing current information that enhances the quality and relevance of your analysis. Web scraping enables you to collect data that might not be readily available through traditional APIs or databases, offering a competitive edge by incorporating unique and comprehensive insights. Moreover, it automates the data collection process, saving time and resources while ensuring a scalable approach to continuously updating and maintaining your datasets.\n",
    "\n",
    "Ethical web scraping involves respecting website terms of service, avoiding overloading servers, and ensuring that the collected data is used responsibly and in compliance with privacy laws and regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588254e6-2157-47bd-b21e-9c55888b654d",
   "metadata": {},
   "source": [
    "Use Python, ```requests```, ```BeautifulSoup``` and/or ```pandas``` to scrape web data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef6a9f-888c-4b46-839f-e6c2055a3b44",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "afe18cce-f661-44e3-966a-f6253025b02a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T14:59:40.539019Z",
     "start_time": "2025-06-23T14:59:39.383648Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6df7c955-ae58-4fb4-9e77-fa945b5a2d0e",
   "metadata": {},
   "source": [
    "## Define the Target URL"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6227173-b844-4330-ab17-fc4ed20c546c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:00:04.544409Z",
     "start_time": "2025-06-23T15:00:04.540409Z"
    }
   },
   "source": "url = \"https://www.timeanddate.de/wetter/niederlande/amsterdam/rueckblick?month=5&year=2015\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "e0aa53df-3c02-43b4-8810-aaac3a0685ab",
   "metadata": {},
   "source": [
    "## Send a Request to the Website\n",
    "\n",
    "Do not forget to check the response status code"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd7ee575-a612-410c-8d4b-0d201e220eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:00:07.705518Z",
     "start_time": "2025-06-23T15:00:07.517501Z"
    }
   },
   "source": [
    "response = requests.get(url)\n",
    "html = response.text\n",
    "print(\"Status Code:\", response.status_code)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7fc3ab17-c3a3-4886-a600-54ff193ea1f8",
   "metadata": {},
   "source": [
    "## Parse the HTML Content\n",
    "\n",
    "Use a library to access the HTMl content"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb23d1a5-ef0e-4512-b31e-a37a83a2effe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:00:11.900128Z",
     "start_time": "2025-06-23T15:00:11.860126Z"
    }
   },
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c7cbb259-602c-4644-a9ac-41d8a7fe0eb3",
   "metadata": {},
   "source": [
    "## Identify the Data to be Scraped\n",
    "\n",
    "Write a couple of sentence on the data you want to scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde90e0-854f-4053-8362-c885e2c5e457",
   "metadata": {},
   "source": [
    "### Identify the Data to be Scraped\n",
    "### TODO: I want to scrape historical temperature data for Amsterdam from timeanddate.de,\n",
    "### where each entry includes a timestamp and the corresponding temperature in °C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb64f4-3159-4782-9425-efbec82b7592",
   "metadata": {},
   "source": [
    "## Extract Data\n",
    "\n",
    "Find specific elements and extract text or attributes from elements (handle pagination if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "id": "67076819-665f-43c6-9811-1218696a1b88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:39:36.957339Z",
     "start_time": "2025-06-23T15:39:36.927432Z"
    }
   },
   "source": [
    "# Wetterdaten im Script als JSON suchen (regulärer Ausdruck)\n",
    "match = re.search(r'\"temp\":(\\[.*?\\])', html)\n",
    "\n",
    "if match:\n",
    "    temp_data = json.loads(match.group(1))\n",
    "\n",
    "    # Daten verarbeiten\n",
    "    records = []\n",
    "    for entry in temp_data:\n",
    "        timestamp = entry[\"date\"] / 1000  # ms -> s\n",
    "        dt = datetime.fromtimestamp(timestamp)\n",
    "        records.append({\"Date\": dt.strftime('%Y-%m-%d %H:%M'), \"Temperature\": entry[\"temp\"]})\n",
    "        \n",
    "        # In DataFrame speichern\n",
    "    df = pd.DataFrame(records)\n",
    "    print(df.describe())\n",
    "    print(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Temperature\n",
      "count  1465.000000\n",
      "mean     12.242321\n",
      "std       3.041491\n",
      "min       3.000000\n",
      "25%      10.000000\n",
      "50%      12.000000\n",
      "75%      14.000000\n",
      "max      24.000000\n",
      "               Date  Temperature\n",
      "0  2015-05-01 02:25            6\n",
      "1  2015-05-01 02:55            7\n",
      "2  2015-05-01 03:25            7\n",
      "3  2015-05-01 03:55            7\n",
      "4  2015-05-01 04:25            6\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "15439eda-7402-41f6-9322-2ddecf24bf91",
   "metadata": {},
   "source": [
    "## Store Data in a Structured Format\n",
    "\n",
    "Give a brief overview of the data collected (e.g. count, fields, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48684760-3804-4ba0-a989-bbbf89383886",
   "metadata": {},
   "outputs": [],
   "source": [
    "Die Daten bestehen aus 2 Spalten:\n",
    "- `Date`: Datum und Uhrzeit im Format `YYYY-MM-DD HH:MM`\n",
    "- `Temperature`: Temperatur in °C\n",
    "\n",
    "Insgesamt wurden **732** erfasst, die über 2 Wochen verteilt sind und eine Zeitreihe bilden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517c66d-3f57-4da9-b3cd-db55c85585b3",
   "metadata": {},
   "source": [
    "## Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "03309800-94f3-4529-bb22-3a44a0fb5242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:00:58.946647Z",
     "start_time": "2025-06-23T15:00:58.931022Z"
    }
   },
   "source": [
    "# Speichern als CSV\n",
    "if match:\n",
    "    df.to_csv(\"amsterdam_weather_may2015.csv\", index=False)\n",
    "    print(\"Daten gespeichert in 'amsterdam_weather_time_series.csv'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten gespeichert in 'amsterdam_weather_time_series.csv'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gather Data for Presentation",
   "id": "31eaec416accf1d2"
  },
  {
   "cell_type": "code",
   "id": "dc6897a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T19:57:37.157319Z",
     "start_time": "2025-06-23T19:57:28.055813Z"
    }
   },
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Städte definieren (URL-Pfade)\n",
    "cities = {\n",
    "    \"Amsterdam\": \"niederlande/amsterdam\",\n",
    "    \"Berlin\": \"deutschland/berlin\",\n",
    "    \"Paris\": \"frankreich/paris\",\n",
    "    \"Madrid\": \"spanien/madrid\",\n",
    "    \"Wien\": \"oesterreich/wien\"\n",
    "}\n",
    "\n",
    "# Gesamtdatenliste\n",
    "all_records = []\n",
    "\n",
    "for city_name, city_path in cities.items():\n",
    "    for month in range(1, 13):\n",
    "        url = f\"https://www.timeanddate.de/wetter/{city_path}/rueckblick?month={month}&year=2020\"\n",
    "        response = requests.get(url)\n",
    "        html = response.text\n",
    "\n",
    "        # Temperaturdaten als JSON aus HTML extrahieren\n",
    "        match = re.search(r'\"temp\":(\\[.*?\\])', html)\n",
    "        if match:\n",
    "            try:\n",
    "                temp_data = json.loads(match.group(1))\n",
    "                for entry in temp_data:\n",
    "                    timestamp = entry[\"date\"] / 1000  # ms → s\n",
    "                    dt = datetime.fromtimestamp(timestamp)\n",
    "\n",
    "                    # Nur speichern, wenn Temperatur vorhanden\n",
    "                    if \"temp\" in entry:\n",
    "                        all_records.append({\n",
    "                            \"City\": city_name,\n",
    "                            \"Date\": dt.strftime('%Y-%m-%d %H:%M'),\n",
    "                            \"Temperature\": entry[\"temp\"]\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Fehler beim Verarbeiten von {city_name}, Monat {month}: {e}\")\n",
    "        else:\n",
    "            print(f\"❌ Keine Temperaturdaten für {city_name}, Monat {month}\")\n",
    "\n",
    "# In DataFrame umwandeln\n",
    "df = pd.DataFrame(all_records)\n",
    "\n",
    "# In CSV speichern\n",
    "df.to_csv(\"weather_europe_2020.csv\", index=False)\n",
    "print(\"✅ Fertig! Daten gespeichert in 'weather_europe_2015.csv'\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fertig! Daten gespeichert in 'weather_europe_2015.csv'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T15:53:46.023964Z",
     "start_time": "2025-06-23T15:53:45.974361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(all_records)\n",
    "print(df.head())\n",
    "print(\"Datensätze gesamt:\", len(df))\n"
   ],
   "id": "1bfae994872fdc98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City              Date  Temperature\n",
      "0  Amsterdam  2015-01-01 01:25            4\n",
      "1  Amsterdam  2015-01-01 01:55            4\n",
      "2  Amsterdam  2015-01-01 02:25            3\n",
      "3  Amsterdam  2015-01-01 02:55            3\n",
      "4  Amsterdam  2015-01-01 03:25            2\n",
      "Datensätze gesamt: 78768\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
